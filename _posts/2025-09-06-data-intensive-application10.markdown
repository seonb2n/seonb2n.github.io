---
layout: post
title: "데이터 중심 애플리케이션 설계10"
date: 2025-09-06 14:02:01 +0900
categories: [ 독서 ]
---

---

# 일괄 처리

## 개요

10장에서는 요청-응답 방식의 온라인 시스템과 대비되는 **배치 처리 시스템**에 대해 다룹니다. 배치 처리는 대규모 데이터를 처리하여 파생 데이터를 생성하는 핵심 구성 요소입니다.

## 1. 배치 처리의 정의와 특징

### 핵심 개념
- **고정된(bounded) 크기**의 대량 데이터를 입력으로 처리
- 입력 데이터를 수정하지 않고 새로운 데이터를 출력
- **처리량(throughput)**이 응답시간보다 중요
- 사용자가 기다리지 않음 (수분~수일 소요 가능)

### 온라인 시스템과의 차이점
```
온라인 시스템: 요청 → 빠른 응답 (밀리초~초)
배치 시스템: 대용량 입력 → 처리 → 결과 출력 (분~일)
```

## 2. Unix 도구를 이용한 배치 처리

### Unix 철학의 핵심
- **모듈성**: 각 프로그램은 한 가지 일을 잘함
- **재사용성**: 프로그램들을 조합 가능
- **파이프**: 프로그램 간 연결을 통한 데이터 흐름

### 실제 예시: 로그 분석
```bash
# Nginx 액세스 로그에서 상위 5개 URL 추출
cat /var/log/nginx/access.log | \
awk '{print $7}' | \
sort | \
uniq -c | \
sort -nr | \
head -5
```

**각 단계별 역할:**
- `cat`: 파일 읽기
- `awk`: URL 필드 추출
- `sort`: 정렬
- `uniq -c`: 중복 제거 및 카운팅
- `sort -nr`: 숫자 역순 정렬
- `head -5`: 상위 5개 선택

### Unix 도구의 장점
- **불변성**: 원본 파일을 수정하지 않음
- **자동 병렬화**: 파이프를 통한 스트리밍 처리
- **단순함**: 복잡한 분석을 간단한 명령어로 수행

## 3. MapReduce 작업 실행

### 기본 아키텍처
```
입력 데이터 → Map 태스크 → 중간 결과 → Reduce 태스크 → 최종 출력
```

### 핵심 원칙: 데이터 가까이에서 계산
- **데이터 지역성**: 입력 파일이 저장된 머신에서 맵퍼 실행
- **네트워크 부하 감소**: 데이터 이동 최소화
- **HDFS와의 협력**: 분산 파일 시스템과 긴밀한 통합

### MapReduce 처리 과정
1. **분할**: 입력 데이터를 청크로 나눔
2. **맵핑**: 각 청크를 병렬로 처리
3. **셔플링**: 중간 결과를 키별로 그룹화
4. **리듀싱**: 그룹화된 데이터를 집계

### 웹 로그 분석 예시
```
맵퍼 입력: "192.168.1.1 - - [10/Oct/2000:13:55:36] GET /index.html 200 2326"
맵퍼 출력: ("/index.html", 1)

리듀서 입력: ("/index.html", [1, 1, 1, 1, 1])
리듀서 출력: ("/index.html", 5)
```

## 4. 조인 연산과 워크플로우

### 정렬-병합 조인(Sort-Merge Join)
**문제**: 사용자 활동 로그와 사용자 프로필을 연결하여 연령대별 페이지 방문 분석

**해결 과정:**
1. **맵퍼**: 양쪽 데이터셋에서 사용자 ID를 키로 추출
2. **셔플**: 동일한 사용자 ID를 같은 리듀서로 전송
3. **리듀서**: 사용자별로 활동 데이터와 프로필 데이터 조인

```
활동 로그: (user_id: 123, page: "/products", timestamp: "2024-01-15T10:30:00")
사용자 프로필: (user_id: 123, birth_year: 1990, location: "Seoul")

조인 결과: (user_id: 123, page: "/products", age_group: "30-34")
```

### 핫스팟 문제
- **원인**: 유명인의 활동처럼 특정 키에 데이터 집중
- **결과**: 불균형한 워크로드로 전체 작업 지연
- **해결책**: 스큐 조인 기능 사용 (키를 랜덤하게 분할)

### 워크플로우 체이닝
```
로그 데이터 → [작업 1: 정제] → 정제된 데이터 → [작업 2: 집계] → 보고서
                    ↓
               중간 저장소 (HDFS)
```

## 5. 배치 처리의 불변성과 장점

### 불변성(Immutability)의 이점
- **쉬운 롤백**: 오류 발생 시 전체 작업 재실행으로 복구
- **자동 재시도**: 태스크 실패 시 프레임워크가 자동으로 재시작
- **부분 실패 허용**: 실패한 태스크의 출력만 폐기하고 재실행

### 스키마 온 리드(Schema-on-Read)
**스시 원칙**: "원시 데이터가 더 좋다(raw data is better)"
- 원시 데이터를 표준화하지 않고 그대로 저장
- 소비자가 필요에 따라 데이터를 해석
- 다양한 분석 요구사항에 유연하게 대응

```
원시 로그: 192.168.1.1 - - [10/Oct/2000:13:55:36] GET /index.html 200 2326

분석 1: 시간대별 트래픽 분석 → 타임스탬프 추출
분석 2: 인기 페이지 분석 → URL 추출
분석 3: 에러 분석 → 상태 코드 추출
```

## 6. 오류 허용(Fault Tolerance)

### 설계 철학
MapReduce는 **잦은 태스크 종료를 허용**하도록 설계됨
- 혼합 사용 데이터센터에서 낮은 우선순위 작업이 선점될 수 있음
- 리소스 활용도 향상을 위한 유연성 제공

### 오류 허용 메커니즘
1. **입력 불변성**: 원본 데이터 보호
2. **출력 폐기**: 실패한 태스크의 부분 출력 제거
3. **재실행**: 다른 머신에서 태스크 재시작
4. **정확히 한 번 처리**: 장애가 없었던 것처럼 결과 보장

## 7. MapReduce를 넘어서는 기술들

### 고수준 프로그래밍 모델
**문제**: MapReduce 직접 프로그래밍의 복잡성

**해결책**:
- **Pig**: 데이터 흐름 언어
- **Hive**: SQL 유사 인터페이스
- **Cascading**: Java API
- **Crunch**: Java/Scala API

### 차세대 데이터 흐름 엔진

#### Apache Spark/Flink의 개선사항
- **메모리 활용**: 중간 상태를 메모리에 유지
- **파이프라인 실행**: 단계별 완료를 기다리지 않고 점진적 처리
- **성능 향상**: 디스크 I/O 감소로 속도 개선

```
MapReduce: Map → 디스크 저장 → Reduce → 디스크 저장 → 다음 작업
Spark/Flink: Map → 메모리 → Reduce → 메모리 → 다음 작업
```

### 그래프 처리 모델(Pregel)
**특징**:
- 정점(vertex) 중심의 처리 모델
- 메시지 전달을 통한 통신
- 체크포인트를 통한 내구성 보장

**활용 사례**:
- PageRank 알고리즘
- 최단 경로 탐색
- 소셜 네트워크 분석

## 8. 서버 개발자를 위한 핵심 포인트

### 시스템 설계 시 고려사항
1. **처리량 vs 지연시간**: 배치는 처리량 우선
2. **데이터 지역성**: 네트워크 비용 최소화
3. **장애 허용**: 부분 실패를 고려한 설계
4. **확장성**: 수평적 확장 가능한 아키텍처

### 파생 데이터 시스템
배치 처리의 결과물들:
- **보고서**: 차트, 순위 목록
- **검색 인덱스**: Elasticsearch 인덱스 생성
- **추천 시스템**: 머신러닝 모델 학습
- **집계 테이블**: 데이터 웨어하우스용 요약 데이터

### 애자일 개발과의 연관성
- **빠른 실험**: 불변성으로 인한 안전한 롤백
- **반복적 개선**: 쉬운 파이프라인 수정
- **A/B 테스트**: 동일 데이터로 다른 알고리즘 비교
