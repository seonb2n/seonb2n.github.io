---
layout: post
title: "LLM Agent ì§ì ‘ ë§Œë“¤ì–´ë³´ê¸° 01"
date: 2025-06-16 09:53:01 +0900
categories: [ í”„ë¡œì íŠ¸, LLM-Agent ]
---

---


> í™˜ê²½
> <br/> window
> <br/> 4070 super
> <br/> 32G ë©”ëª¨ë¦¬

## ollama ì„¤ì¹˜

ollama ëŠ” ë¡œì»¬ì—ì„œ LLM ëª¨ë¸ì„ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ë„êµ¬ì…ë‹ˆë‹¤. Docker ì²˜ëŸ¼ LLM ëª¨ë¸ì„ ì‰½ê²Œ ì„¤ì¹˜ ë° êµ¬ë™í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í”Œë«í¼ì´ë¼ê³  ì´í•´í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

<br /> ì£¼ì†Œ : https://ollama.com/download/windows

![Desktop View](/assets/img/2025-06-16/img01.png){: width="372" height="372" }

> ê·€ì—¬ì›€ ã…‹ã…‹

## ëª¨ë¸ ì„ íƒ

ë¡œì»¬ì—ì„œ êµ¬ë™í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— VRAM ì‚¬ìš©ëŸ‰ì„ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.

### 1. DeepSeek Coder V2 Lite 16B

| í•­ëª© | ìƒì„¸ |
|-----|------|
| **í¬ê¸°** | 16B íŒŒë¼ë¯¸í„° |
| **VRAM ì‚¬ìš©ëŸ‰** | 10-12GB (Q4_K_M ì–‘ìí™”) |
| **íŠ¹í™” ë¶„ì•¼** | ì½”ë“œ ìƒì„±, ë””ë²„ê¹…, ì½”ë“œ ì„¤ëª… |
| **ì–¸ì–´ ì§€ì›** | Python, JavaScript, Java, C++ ë“± 80+ ì–¸ì–´ |
| **í•œêµ­ì–´ ì§€ì›** | â­â­â­â­ (ì–‘í˜¸) |
| **ì½”ë“œ í’ˆì§ˆ** | â­â­â­â­â­ (ë§¤ìš° ìš°ìˆ˜) |
| **ì¶”ë¡  ì†ë„** | â­â­â­â­ (ë¹ ë¦„) |
| **ì¥ì ** | ì‹¤ì œ ë™ì‘í•˜ëŠ” ì½”ë“œ ìƒì„±, ë³µì¡í•œ ë¡œì§ êµ¬í˜„ ê°€ëŠ¥, ìµœì‹  í”„ë ˆì„ì›Œí¬ ì§€ì› |
| **ë‹¨ì ** | ìƒëŒ€ì ìœ¼ë¡œ í° ëª¨ë¸ í¬ê¸°, ë²”ìš© ëŒ€í™”ëŠ” ë‹¤ì†Œ ì•„ì‰¬ì›€ |

---

### 2. Qwen2.5 Coder 14B

| í•­ëª© | ìƒì„¸ |
|-----|------|
| **í¬ê¸°** | 14B íŒŒë¼ë¯¸í„° |
| **VRAM ì‚¬ìš©ëŸ‰** | 9-11GB (Q4_K_M ì–‘ìí™”) |
| **íŠ¹í™” ë¶„ì•¼** | ì½”ë“œ ìƒì„±, ìˆ˜í•™ì  ì¶”ë¡  |
| **ì–¸ì–´ ì§€ì›** | ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ |
| **í•œêµ­ì–´ ì§€ì›** | â­â­â­â­â­ (ìš°ìˆ˜) |
| **ì½”ë“œ í’ˆì§ˆ** | â­â­â­â­ (ìš°ìˆ˜) |
| **ì¶”ë¡  ì†ë„** | â­â­â­â­ (ë¹ ë¦„) |
| **ì¥ì ** | í•œêµ­ì–´ ì´í•´ë„ ë›°ì–´ë‚¨, ìˆ˜í•™ì  ë¡œì§ êµ¬í˜„ ìš°ìˆ˜, ìµœì‹  ëª¨ë¸ |
| **ë‹¨ì ** | ë³µì¡í•œ ì•± êµ¬ì¡° ìƒì„± ì‹œ ì¼ê´€ì„± ë¶€ì¡±, ìƒëŒ€ì ìœ¼ë¡œ ìƒˆë¡œìš´ ëª¨ë¸ |

---

### 3. CodeLlama 13B Instruct

| í•­ëª© | ìƒì„¸ |
|-----|------|
| **í¬ê¸°** | 13B íŒŒë¼ë¯¸í„° |
| **VRAM ì‚¬ìš©ëŸ‰** | 8-10GB (Q4_K_M ì–‘ìí™”) |
| **íŠ¹í™” ë¶„ì•¼** | ì½”ë“œ ìƒì„±, ì½”ë“œ ì™„ì„± |
| **ì–¸ì–´ ì§€ì›** | Python, C++, Java, JavaScript ë“± |
| **í•œêµ­ì–´ ì§€ì›** | â­â­â­ (ë³´í†µ) |
| **ì½”ë“œ í’ˆì§ˆ** | â­â­â­â­ (ìš°ìˆ˜) |
| **ì¶”ë¡  ì†ë„** | â­â­â­â­â­ (ë§¤ìš° ë¹ ë¦„) |
| **ì¥ì ** | ê²€ì¦ëœ ì•ˆì •ì„±, ë¹ ë¥¸ ì¶”ë¡  ì†ë„, ì½”ë“œ ì™„ì„± ê¸°ëŠ¥ ìš°ìˆ˜ |
| **ë‹¨ì ** | í•œêµ­ì–´ ì´í•´ë„ ì œí•œì , ìµœì‹  í”„ë ˆì„ì›Œí¬ ì§€ì‹ ë¶€ì¡± |

---

### 4. Llama 3.1 8B Instruct

| í•­ëª© | ìƒì„¸ |
|-----|------|
| **í¬ê¸°** | 8B íŒŒë¼ë¯¸í„° |
| **VRAM ì‚¬ìš©ëŸ‰** | 6-8GB (Q4_K_M ì–‘ìí™”) |
| **íŠ¹í™” ë¶„ì•¼** | ë²”ìš© ëŒ€í™”, ì¼ë°˜ì  ì½”ë”© |
| **ì–¸ì–´ ì§€ì›** | ì£¼ìš” í”„ë¡œê·¸ë˜ë° ì–¸ì–´ |
| **í•œêµ­ì–´ ì§€ì›** | â­â­â­â­ (ì–‘í˜¸) |
| **ì½”ë“œ í’ˆì§ˆ** | â­â­â­ (ë³´í†µ) |
| **ì¶”ë¡  ì†ë„** | â­â­â­â­â­ (ë§¤ìš° ë¹ ë¦„) |
| **ì¥ì ** | ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ë¹ ë¥¸ ì‘ë‹µ ì†ë„, ë²”ìš©ì„± ì¢‹ìŒ |
| **ë‹¨ì ** | ë³µì¡í•œ ì½”ë“œ ìƒì„± ëŠ¥ë ¥ ì œí•œ, ì½”ë“œ ì „ìš© ëª¨ë¸ ëŒ€ë¹„ í’ˆì§ˆ ë–¨ì–´ì§ |

---

### 5. Wizard Coder 15B

| í•­ëª© | ìƒì„¸ |
|-----|------|
| **í¬ê¸°** | 15B íŒŒë¼ë¯¸í„° |
| **VRAM ì‚¬ìš©ëŸ‰** | 10-12GB (Q4_K_M ì–‘ìí™”) |
| **íŠ¹í™” ë¶„ì•¼** | ì½”ë“œ ìƒì„±, ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ |
| **ì–¸ì–´ ì§€ì›** | Python, JavaScript, C++ ë“± |
| **í•œêµ­ì–´ ì§€ì›** | â­â­ (ì œí•œì ) |
| **ì½”ë“œ í’ˆì§ˆ** | â­â­â­â­ (ìš°ìˆ˜) |
| **ì¶”ë¡  ì†ë„** | â­â­â­ (ë³´í†µ) |
| **ì¥ì ** | ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ëŠ¥ë ¥ ìš°ìˆ˜, ì½”ë“œ ìµœì í™” ì œì•ˆ |
| **ë‹¨ì ** | í•œêµ­ì–´ ì§€ì› ë¶€ì¡±, ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦° ì¶”ë¡  |

### ğŸ¥‡ 1ìˆœìœ„: DeepSeek Coder V2 Lite 16B
**ì´ìœ **: ì½”ë“œ ìƒì„± í’ˆì§ˆ, í•œêµ­ì–´ ì§€ì›, ìµœì‹ ì„±ì˜ ìµœì  ì¡°í•©

### ğŸ¥ˆ 2ìˆœìœ„: Qwen2.5 Coder 14B
**ì´ìœ **: í•œêµ­ì–´ ì´í•´ë„ê°€ ê°€ì¥ ë›°ì–´ë‚˜ê³ , ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ ì ë‹¹

### ğŸ¥‰ 3ìˆœìœ„: Llama 3.1 8B
**ì´ìœ **: ë©”ëª¨ë¦¬ ë¶€ì¡±í•˜ê±°ë‚˜ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ì´ í•„ìš”í•œ ê²½ìš°

ìœ„ì™€ ê°™ì€ ì´ìœ ë¡œ DeepSeek Coder v2 ë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤. ollama ë¥¼ í†µí•´ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œ ë°›ê³  êµ¬ë™ì‹œì¼°ìŠµë‹ˆë‹¤.

```shell

PS C:\Windows\System32> ollama pull deepseek-coder-v2:16b-lite-instruct-q4_K_M

```

### ë‹¤ìš´ë¡œë“œ ë°›ì€ ëª¨ë¸ í…ŒìŠ¤íŠ¸

```shell

PS C:\Users\user> ollama list
NAME                                          ID              SIZE     MODIFIED
deepseek-coder-v2:16b-lite-instruct-q4_K_M    dac6ff6589c9    10 GB    32 seconds ago
PS C:\Users\user> ollama run deepseek-coder-v2:16b-lite-instruct-q4_K_M
>>> ì•ˆë…•í•˜ì„¸ìš”! íŒŒì´ì¬ìœ¼ë¡œ ê°„ë‹¨í•œ Hello World í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
 ì•ˆë…•í•˜ì„¸ìš”! ë°˜ê°€ì›Œìš”. íŒŒì´ì¬ìœ¼ë¡œ ê°„ë‹¨í•œ "Hello World" í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì•„ë˜ëŠ” íŒŒì´ì¬ ì½”ë“œì˜ ì˜ˆì œì…ë‹ˆ
ë‹¤:

print("Hello, World!")

ì´ ì½”ë“œë¥¼ `hello_world.py` íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , í„°ë¯¸ë„ì´ë‚˜ ëª…ë ¹ í”„ë¡¬í”„íŠ¸ì—ì„œ í•´ë‹¹ íŒŒì¼ì„ ì‹¤í–‰ì‹œí‚¤ë©´ "Hello, World!"ë¼ëŠ”
ë©”ì‹œì§€ê°€ ì½˜ì†”ì— ì¶œë ¥ë©ë‹ˆë‹¤.

ë§Œì•½ í„°ë¯¸ë„ì´ë‚˜ ëª…ë ¹ í”„ë¡¬íŠ¸ì—ì„œ ì‘ì—…í•˜ê³  ìˆëŠ”ë°, `hello_world.py` íŒŒì¼ì„ ì–´ë””ì— ì €ì¥í•´ì•¼ í•˜ëŠ”ì§€ ëª¨ë¥´ê² ë‹¤ë©´, ë³´í†µ ì‚¬
ìš©ìì˜ í™ˆ ë””ë ‰í† ë¦¬(`~`)ë‚˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì €ì¥í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ ìœ„ì¹˜ì— íŒŒì¼ì„ ì €ì¥í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, í™ˆ ë””ë ‰í† ë¦¬ì— `Documents`ë‚˜ `Desktop`ê³¼ ê°™ì€ í´ë”ë¥¼ ë§Œë“¤ê³ , ê·¸ê³³ì— íŒŒì¼ì„ ì €ì¥í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.

íŒŒì´ì¬ìœ¼ë¡œ ë¬´ì–¸ê°€ë¥¼ ì‹œì‘í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì‰½ê³ , ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤! ê·¸ë™ì•ˆ íŒŒì´ì¬ì„ ë°°ì›Œë³´ì„¸ìš”.

>>> /bye

```

ì˜ êµ¬ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### python ì—ì„œë„ í™•ì¸í•´ë³´ê¸°

```python


import requests
import json
import time

# Ollama API ì„¤ì •
OLLAMA_URL = "http://localhost:11434"
MODEL_NAME = "deepseek-coder-v2:16b-lite-instruct-q4_K_M"


def test_ollama_connection():
    """Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags")
        if response.status_code == 200:
            models = response.json()
            print("âœ… Ollama ì„œë²„ ì—°ê²° ì„±ê³µ!")
            print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
            for model in models.get('models', []):
                print(f"  - {model['name']}")
            return True
        else:
            print(f"âŒ Ollama ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'ollama serve' ëª…ë ¹ìœ¼ë¡œ ì„œë²„ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”.")
        return False
    except Exception as e:
        print(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


def test_model_generation():
    """ëª¨ë¸ ì½”ë“œ ìƒì„± í…ŒìŠ¤íŠ¸"""
    print(f"\nğŸ¤– ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘: {MODEL_NAME}")

    # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
    prompt = """
íŒŒì´ì¬ìœ¼ë¡œ ì£¼ì‹ ê°€ê²©ì„ ì¡°íšŒí•˜ëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
í•¨ìˆ˜ëª…ì€ get_stock_priceì´ê³ , ì¢…ëª© ì½”ë“œë¥¼ ì…ë ¥ë°›ì•„ì„œ í˜„ì¬ê°€ë¥¼ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
yfinance ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.
"""

    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False
    }

    try:
        print("â³ ì½”ë“œ ìƒì„± ì¤‘... (30ì´ˆ-2ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        start_time = time.time()

        response = requests.post(
            f"{OLLAMA_URL}/api/generate",
            json=payload,
            timeout=120  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
        )

        end_time = time.time()

        if response.status_code == 200:
            result = response.json()
            generated_code = result.get('response', '')

            print(f"âœ… ì½”ë“œ ìƒì„± ì„±ê³µ! (ì†Œìš”ì‹œê°„: {end_time - start_time:.1f}ì´ˆ)")
            print("\n" + "=" * 50)
            print("ğŸ“ ìƒì„±ëœ ì½”ë“œ:")
            print("=" * 50)
            print(generated_code)
            print("=" * 50)
            return True
        else:
            print(f"âŒ ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {response.status_code}")
            print(f"ì‘ë‹µ: {response.text}")
            return False

    except requests.exceptions.Timeout:
        print("â° ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (2ë¶„). ëª¨ë¸ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        print(f"âŒ ì½”ë“œ ìƒì„± ì˜¤ë¥˜: {e}")
        return False


def test_langchain_integration():
    """LangChain ì—°ë™ í…ŒìŠ¤íŠ¸"""
    try:
        from langchain_community.llms import Ollama

        print(f"\nğŸ”— LangChain ì—°ë™ í…ŒìŠ¤íŠ¸")

        # LangChain Ollama ê°ì²´ ìƒì„±
        llm = Ollama(model=MODEL_NAME)

        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        prompt = "íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."

        print("â³ LangChainìœ¼ë¡œ ì½”ë“œ ìƒì„± ì¤‘...")
        start_time = time.time()

        response = llm.invoke(prompt)

        end_time = time.time()

        print(f"âœ… LangChain ì—°ë™ ì„±ê³µ! (ì†Œìš”ì‹œê°„: {end_time - start_time:.1f}ì´ˆ)")
        print("\n" + "=" * 30)
        print("ğŸ“ LangChain ì‘ë‹µ:")
        print("=" * 30)
        print(response)
        print("=" * 30)
        return True

    except ImportError:
        print("âŒ LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ì„¤ì¹˜ ëª…ë ¹: pip install langchain langchain-community")
        return False
    except Exception as e:
        print(f"âŒ LangChain ì—°ë™ ì‹¤íŒ¨: {e}")
        return False


def main():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ Ollama ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print(f"ğŸ“ ëŒ€ìƒ ëª¨ë¸: {MODEL_NAME}")
    print(f"ğŸŒ Ollama URL: {OLLAMA_URL}")
    print("-" * 60)

    # 1. ì—°ê²° í…ŒìŠ¤íŠ¸
    if not test_ollama_connection():
        print("\nâŒ Ollama ì„œë²„ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return

    # 2. ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
    if not test_model_generation():
        print("\nâŒ ëª¨ë¸ ì½”ë“œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    # 3. LangChain ì—°ë™ í…ŒìŠ¤íŠ¸
    if not test_langchain_integration():
        print("\nâŒ LangChain ì—°ë™ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return

    print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("âœ… Ollama ì„œë²„ ì—°ê²°ë¨")
    print("âœ… ëª¨ë¸ ì½”ë“œ ìƒì„± ì‘ë™í•¨")
    print("âœ… LangChain ì—°ë™ ì„±ê³µ")
    print("\në‹¤ìŒ ë‹¨ê³„: FastAPI ì—ì´ì „íŠ¸ êµ¬í˜„ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")


if __name__ == "__main__":
    main()

```

**ê²°ê³¼**

```shell

==============================

ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!
âœ… Ollama ì„œë²„ ì—°ê²°ë¨
âœ… ëª¨ë¸ ì½”ë“œ ìƒì„± ì‘ë™í•¨
âœ… LangChain ì—°ë™ ì„±ê³µ


```


## Fast API ì„¸íŒ…

ì½”ë”© agent ë¥¼ ë§Œë“¤ ì˜ˆì •ì´ë‹ˆ, ìš”ì²­ì„ ë°›ì•„ì¤„ ì„œë²„ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤. ê°„ë‹¨í•˜ê²Œ FastAPI ë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ í•˜ê³ , ë‹¤ìŒê³¼ ê°™ì´ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.
<br />
ë ˆí¬ì§€í† ë¦¬ì˜ ê²½ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. [ê²½ë¡œ](https://github.com/seonb2n/local-ollama-agent)
<br /> ê° íŒŒì¼ë³„ ì½”ë“œëŠ” ìœ„ repository ë¥¼ ì°¸ê³  ë¶€íƒë“œë¦½ë‹ˆë‹¤.

```
code-agent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI ë©”ì¸ ì•±
â”‚   â”œâ”€â”€ models.py            # Pydantic ëª¨ë¸ë“¤
â”‚   â”œâ”€â”€ config.py            # ì„¤ì • ê´€ë¦¬
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ code_agent.py    # LangChain ì—ì´ì „íŠ¸
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ollama_service.py
â”‚   â”‚   â””â”€â”€ file_service.py
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ routes.py        # API ì—”ë“œí¬ì¸íŠ¸
â”œâ”€â”€ generated_code/          # ìƒì„±ëœ ì½”ë“œ ì €ì¥ì†Œ
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                     # í™˜ê²½ë³€ìˆ˜
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

ì´ì œ, ì¤€ë¹„ëœ fastapi ë¥¼ êµ¬ë™ì‹œí‚¤ê³  ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì‘ë‹µì´ ë‚´ë ¤ì˜µë‹ˆë‹¤.

```shell

{
  "success": true,
  "message": "ì½”ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
  "code": " ```python\n# Import necessary libraries\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport requests\nfrom bs4 import BeautifulSoup\n\n# Create a FastAPI app instance\napp = FastAPI()\n\n# Define the data model for stock news (in this case, we'll use a simple string)\nclass StockNews(BaseModel):\n    news: str\n\n# Endpoint to get stock news\n@app.get(\"/stock-news/{company_symbol}\", response_model=StockNews)\ndef get_stock_news(company_symbol: str):\n    try:\n        # Construct the URL for the company's financial news page (example format)\n        url = f\"https://finance.yahoo.com/quote/{company_symbol}/news\"\n        \n        # Send a GET request to fetch the webpage content\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n        \n        # Parse the HTML content of the page using BeautifulSoup\n        soup = BeautifulSoup(response.content, 'html.parser')\n        \n        # Extract news headlines or snippets from the parsed HTML (example selector)\n        # This will vary depending on the website's structure\n        news_element = soup.select_one('.news-list .Mb\\(4px\\)')  # Example CSS selector\n        \n        if not news_element:\n            raise HTTPException(status_code=404, detail=\"News not found\")\n        \n        # Extract the text from the HTML element\n        news = news_element.get_text()\n        \n        # Return the extracted news as a response\n        return StockNews(news=news)\n    \n    except requests.RequestException as e:\n        raise HTTPException(status_code=500, detail=f\"Error fetching news: {e}\")\n\n# Entry point for running the FastAPI app directly\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(app, host=\"127.0.0.1\", port=8000)\n```",
  "filename": "python_app_20250616_231051.py",
  "file_path": "./generated_code\\python_app_20250616_231051.py",
  "dependencies": [
    "fastapi",
    "pydantic",
    "requests",
    "uvicorn",
    "bs4"
  ],
  "execution_time": 20.35269522666931
}

```


![Desktop View](/assets/img/2025-06-16/img02.png){: width="972" height="589" }

ì›í•˜ëŠ”ëŒ€ë¡œ ì½”ë“œë„ ì˜ ìƒì„±ì´ ëìŠµë‹ˆë‹¤.

## ë‹¤ìŒ
<br /> ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œëŠ” Context ë¥¼ ì ìš©í•´ì„œ Agent ì—ê²Œ ì‘ì—… ì§€ì‹œë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œí‚¤ê² ìŠµë‹ˆë‹¤.
